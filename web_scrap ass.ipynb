{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eabd0ea-0d31-4209-9f75-8992d029ddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 1: \n",
    "# Web scraping refers to the automated process of extracting data from websites.\n",
    "# It involves using software tools to extract information from web pages and save it in a structured format like a spreadsheet or database.\n",
    "\n",
    "# USES\n",
    "# Web scraping is used for a variety of purposes, \n",
    "# such as gathering data for market research, competitor analysis, and content aggregation. \n",
    "\n",
    "# AREAS\n",
    "# 1. E-commerce: Many companies use web scraping to gather data on product prices, promotions, and customer reviews. \n",
    "# 2. Social Media: Web scraping can be used to collect data from social media platforms like Twitter, Facebook, and Instagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7eb96d-c0dc-4542-89ff-1b58f767323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 2:\n",
    "# DIFFERENT METHODS:\n",
    "\n",
    "# 1. Manual Scraping: \n",
    "# This involves manually copying and pasting data from web pages into a structured format like a spreadsheet. \n",
    "\n",
    "# 2.Web Scraping Libraries: \n",
    "# These are software tools that provide APIs and other interfaces for extracting data from websites\n",
    "\n",
    "# 3.Data Extraction Services: \n",
    "# These are third-party services that specialize in web scraping and provide APIs for accessing the extracted data. \n",
    "# These services may charge a fee for access to their APIs, but they can be a good option for projects that require large amounts of data or frequent updates.\n",
    "\n",
    "# 4.Browser Extensions: \n",
    "# Some browser extensions like Web Scraper and Data Miner allow users to scrape data from websites without needing to write any code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5a7439-a83e-4fed-a9f2-f64a93e862ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 3:\n",
    "# BREAUTIFUL SOUP\n",
    "# Beautiful Soup is a Python library that is used for web scraping purposes. It is a powerful and flexible library that allows developers to extract data from HTML and XML files. \n",
    "# The library provides a set of tools for parsing and navigating HTML and XML documents, making it easy to extract the relevant data from web pages.\n",
    "\n",
    "# USES\n",
    "# 1 .Beautiful Soup is particularly useful for web scraping because it can handle poorly formatted HTML\n",
    "# and can parse HTML from web pages that have dynamic content\n",
    "\n",
    "# 2. It can also extract data from web pages that are behind login pages, \n",
    "# making it useful for scraping data from sites that require authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce457ee-2e4f-4bd0-8509-ad41ca3490c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 4:\n",
    "# FLASK\n",
    "# 1 .Flask is a lightweight web framework that is often used in web scraping projects for building \n",
    "# web applications to display and interact with the scraped data.\n",
    "\n",
    "# 2.Flask can also be used to build APIs that allow other applications to access the scraped data\n",
    "\n",
    "# 3.Flask is written in Python and is designed to work seamlessly with other Python libraries and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce50904a-317b-43eb-a013-db0cd53c2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 5:\n",
    "# \"Elastic Beanstalk\" service\n",
    "\n",
    "# Elastic Beanstalk is a cloud service provided by Amazon Web Services (AWS) that can be used to deploy and manage web applications.\n",
    "# It is used in several ways:\n",
    "# 1. Scalability: Elastic Beanstalk allows for easy scaling of the web application. \n",
    "# 2. Easy deployment: Elastic Beanstalk makes it easy to deploy the web application to the cloud.\n",
    "# 3. Automatic updates: Elastic Beanstalk can automatically update the web application with the latest code changes. \n",
    "# 4. Cost-effective: Elastic Beanstalk is designed to be cost-effective\n",
    "\n",
    "\n",
    "# \"Codepipeline\" service\n",
    "\n",
    "# CodePipeline is an Amazon Web Services (AWS) service that provides a continuous delivery workflow for applications.\n",
    "# It can be used in sevral ways:\n",
    "# 1.Automated deployment: CodePipeline can be used to automate the deployment of the web application to a web server or cloud service such as Elastic Beanstalk \n",
    "# 2.Testing and validation: CodePipeline can be used to automate the testing and validation of the web application\n",
    "# 3.Customization: CodePipeline can be customized to meet the specific needs of the web scraping project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24a575-910b-4261-887c-5d80c506c0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
